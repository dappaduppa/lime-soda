<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">


<!-- Page 239 -->
<svg x="0" y="0" width="909" height="1286" viewBox="0 0 909 1286" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
style="display: block;margin-left: auto;margin-right: auto;">
<defs>

<style type="text/css"><![CDATA[


.s1_239{
font-size: 30.81px;
font-family: LiberationSerif-Bold_b;
fill: #8E0012;
}
.s2_239{
font-size: 22.01px;
font-family: LiberationSerif_e;
fill: #000000;
}
.s3_239{
font-size: 17.60px;
font-family: LiberationMono_1q;
fill: #000000;
}
.s4_239{
font-size: 13.20px;
font-family: LiberationMono-Bold_1w;
fill: #006699;
}
.s5_239{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #CC00FF;
}
.s6_239{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #000000;
}
.s7_239{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #000088;
}
.s8_239{
font-size: 13.20px;
font-family: LiberationMono-Italic_10;
fill: #0099FF;
}
.s9_239{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #CC3300;
}
.s10_239{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #336666;
}
.s11_239{
font-size: 13.20px;
font-family: LiberationMono-Italic_10;
fill: #CC3300;
}
.s12_239{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #FF6600;
}
.s13_239{
font-size: 13.20px;
font-family: LiberationMono-Bold_1w;
fill: #000000;
}

]]></style>

</defs>
<path d="M0,0
L0,1286
L909,1286
L909,0 Z " 
fill="#FFFFFF" stroke="none" />
<text 
x="55" 
y="81" 
class="s1_239"
>Implementation</text>

<text 
x="55" 
y="122" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.2,0,0,0,0,0,0,0,0,0,0,0,0,-1.2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s2_239"
>Now we have all the pieces we need to build our classifier. First, let’s create a simple</text>

<text 
x="55" 
y="149" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s2_239"
>function to tokenize messages into distinct words. We’ll first convert each message to</text>

<text 
x="55" 
y="177" 
class="s2_239"
>lowercase; use</text>

<text 
x="189" 
y="177" 
class="s3_239"
>re.findall()</text>

<text 
x="321" 
y="177" 
class="s2_239"
>to extract “words” consisting of letters, numbers, and</text>

<text 
x="55" 
y="206" 
class="s2_239"
>apostrophes; and finally use</text>

<text 
x="306" 
y="206" 
class="s3_239"
>set()</text>

<text 
x="364" 
y="206" 
class="s2_239"
>to get just the distinct words:</text>

<text 
x="76" 
y="254" 
class="s4_239"
>def</text>

<text 
x="108" 
y="254" 
class="s5_239"
>tokenize</text>

<text 
x="171" 
y="254" 
class="s6_239"
>(</text>

<text 
x="179" 
y="254" 
class="s7_239"
>message</text>

<text 
x="235" 
y="254" 
class="s6_239"
>):</text>

<text 
x="108" 
y="269" 
class="s7_239"
>message</text>

<text 
x="171" 
y="269" 
class="s6_239"
>=</text>

<text 
x="187" 
y="269" 
class="s7_239"
>message</text>

<text 
x="242" 
y="269" 
class="s6_239"
>.</text>

<text 
x="250" 
y="269" 
class="s7_239"
>lower</text>

<text 
x="290" 
y="269" 
class="s6_239"
>()</text>

<text 
x="487" 
y="269" 
dx="0,0,4.6,0,0,0,0,0,0,0,4.6,0,0,4.6,0,0,0,0,0,0,0,0" 
class="s8_239"
># convert to lowercase</text>

<text 
x="108" 
y="284" 
class="s7_239"
>all_words</text>

<text 
x="187" 
y="284" 
class="s6_239"
>=</text>

<text 
x="203" 
y="284" 
class="s7_239"
>re</text>

<text 
x="219" 
y="284" 
class="s6_239"
>.</text>

<text 
x="227" 
y="284" 
class="s7_239"
>findall</text>

<text 
x="282" 
y="284" 
class="s6_239"
>(</text>

<text 
x="290" 
y="284" 
class="s9_239"
>"[a-z0-9']+"</text>

<text 
x="385" 
y="284" 
class="s6_239"
>,</text>

<text 
x="401" 
y="284" 
class="s7_239"
>message</text>

<text 
x="456" 
y="284" 
class="s6_239"
>)</text>

<text 
x="487" 
y="284" 
dx="0,0,4.6,0,0,0,0,0,0,0,4.6,0,0,0,4.6,0,0,0,0" 
class="s8_239"
># extract the words</text>

<text 
x="108" 
y="300" 
class="s4_239"
>return</text>

<text 
x="163" 
y="300" 
class="s10_239"
>set</text>

<text 
x="187" 
y="300" 
class="s6_239"
>(</text>

<text 
x="195" 
y="300" 
class="s7_239"
>all_words</text>

<text 
x="266" 
y="300" 
class="s6_239"
>)</text>

<text 
x="487" 
y="300" 
dx="0,0,4.6,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0,0" 
class="s8_239"
># remove duplicates</text>

<text 
x="55" 
y="353" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.8,0,0,0,0,0,0,0,0" 
class="s2_239"
>Our second function will count the words in a labeled training set of messages. We’ll have</text>

<text 
x="55" 
y="380" 
class="s2_239"
>it return a dictionary whose keys are words, and whose values are two-element lists</text>

<text 
x="55" 
y="408" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,6.1,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s3_239"
>[spam_count, non_spam_count]</text>

<text 
x="355" 
y="408" 
class="s2_239"
>corresponding to how many times we saw that word in</text>

<text 
x="55" 
y="437" 
class="s2_239"
>both spam and nonspam messages:</text>

<text 
x="76" 
y="483" 
class="s4_239"
>def</text>

<text 
x="108" 
y="483" 
class="s5_239"
>count_words</text>

<text 
x="195" 
y="483" 
class="s6_239"
>(</text>

<text 
x="203" 
y="483" 
class="s7_239"
>training_set</text>

<text 
x="298" 
y="483" 
class="s6_239"
>):</text>

<text 
x="108" 
y="498" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,4.6,0,0,0,4.6,0,0,0,0,0,0,0,0,4.6,0,0,4.6,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0,0,0" 
class="s11_239"
>"""training set consists of pairs (message, is_spam)"""</text>

<text 
x="108" 
y="513" 
class="s7_239"
>counts</text>

<text 
x="163" 
y="513" 
class="s6_239"
>=</text>

<text 
x="179" 
y="513" 
class="s7_239"
>defaultdict</text>

<text 
x="266" 
y="513" 
class="s6_239"
>(</text>

<text 
x="274" 
y="513" 
class="s4_239"
>lambda</text>

<text 
x="322" 
y="513" 
dx="0,0,4.6" 
class="s6_239"
>: [</text>

<text 
x="345" 
y="513" 
class="s12_239"
>0</text>

<text 
x="353" 
y="513" 
class="s6_239"
>,</text>

<text 
x="369" 
y="513" 
class="s12_239"
>0</text>

<text 
x="377" 
y="513" 
class="s6_239"
>])</text>

<text 
x="108" 
y="529" 
class="s4_239"
>for</text>

<text 
x="140" 
y="529" 
class="s7_239"
>message</text>

<text 
x="195" 
y="529" 
class="s6_239"
>,</text>

<text 
x="211" 
y="529" 
class="s7_239"
>is_spam</text>

<text 
x="274" 
y="529" 
class="s13_239"
>in</text>

<text 
x="298" 
y="529" 
class="s7_239"
>training_set</text>

<text 
x="393" 
y="529" 
class="s6_239"
>:</text>

<text 
x="140" 
y="544" 
class="s4_239"
>for</text>

<text 
x="171" 
y="544" 
class="s7_239"
>word</text>

<text 
x="211" 
y="544" 
class="s13_239"
>in</text>

<text 
x="235" 
y="544" 
class="s7_239"
>tokenize</text>

<text 
x="298" 
y="544" 
class="s6_239"
>(</text>

<text 
x="306" 
y="544" 
class="s7_239"
>message</text>

<text 
x="361" 
y="544" 
class="s6_239"
>):</text>

<text 
x="171" 
y="560" 
class="s7_239"
>counts</text>

<text 
x="219" 
y="560" 
class="s6_239"
>[</text>

<text 
x="227" 
y="560" 
class="s7_239"
>word</text>

<text 
x="258" 
y="560" 
class="s6_239"
>][</text>

<text 
x="274" 
y="560" 
class="s12_239"
>0</text>

<text 
x="290" 
y="560" 
class="s4_239"
>if</text>

<text 
x="314" 
y="560" 
class="s7_239"
>is_spam</text>

<text 
x="377" 
y="560" 
class="s4_239"
>else</text>

<text 
x="416" 
y="560" 
class="s12_239"
>1</text>

<text 
x="424" 
y="560" 
dx="0,0,4.6,0" 
class="s6_239"
>] +=</text>

<text 
x="464" 
y="560" 
class="s12_239"
>1</text>

<text 
x="108" 
y="575" 
class="s4_239"
>return</text>

<text 
x="163" 
y="575" 
class="s7_239"
>counts</text>

<text 
x="55" 
y="628" 
class="s2_239"
>Our next step is to turn these counts into estimated probabilities using the smoothing we</text>

<text 
x="55" 
y="655" 
class="s2_239"
>described before. Our function will return a list of triplets containing each word, the</text>

<text 
x="55" 
y="683" 
class="s2_239"
>probability of seeing that word in a spam message, and the probability of seeing that word</text>

<text 
x="55" 
y="710" 
class="s2_239"
>in a nonspam message:</text>

<text 
x="76" 
y="755" 
class="s4_239"
>def</text>

<text 
x="108" 
y="755" 
class="s5_239"
>word_probabilities</text>

<text 
x="250" 
y="755" 
class="s6_239"
>(</text>

<text 
x="258" 
y="755" 
class="s7_239"
>counts</text>

<text 
x="306" 
y="755" 
class="s6_239"
>,</text>

<text 
x="322" 
y="755" 
class="s7_239"
>total_spams</text>

<text 
x="408" 
y="755" 
class="s6_239"
>,</text>

<text 
x="424" 
y="755" 
class="s7_239"
>total_non_spams</text>

<text 
x="543" 
y="755" 
class="s6_239"
>,</text>

<text 
x="559" 
y="755" 
class="s7_239"
>k</text>

<text 
x="567" 
y="755" 
class="s6_239"
>=</text>

<text 
x="574" 
y="755" 
class="s12_239"
>0.5</text>

<text 
x="598" 
y="755" 
class="s6_239"
>):</text>

<text 
x="108" 
y="771" 
dx="0,0,0,0,0,0,0,0,4.6,0,0,0,4.6,0,0,0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,4.6,0,4.6,0,0,0,0,4.6,0,0,4.6,0,0,0,0,0,0,0" 
class="s11_239"
>"""turn the word_counts into a list of triplets</text>

<text 
x="108" 
y="786" 
dx="0,0,0,4.6,0,0,0,4.6,0,4.6,0,0,0,0,0,4.6,0,0,0,4.6,0,0,0,4.6,0,4.6,0,0,0,0,0,0,0,0" 
class="s11_239"
>w, p(w | spam) and p(w | ~spam)"""</text>

<text 
x="108" 
y="802" 
class="s4_239"
>return</text>

<text 
x="163" 
y="802" 
class="s6_239"
>[(</text>

<text 
x="179" 
y="802" 
class="s7_239"
>w</text>

<text 
x="187" 
y="802" 
class="s6_239"
>,</text>

<text 
x="179" 
y="817" 
class="s6_239"
>(</text>

<text 
x="187" 
y="817" 
class="s7_239"
>spam</text>

<text 
x="227" 
y="817" 
class="s6_239"
>+</text>

<text 
x="242" 
y="817" 
class="s7_239"
>k</text>

<text 
x="250" 
y="817" 
dx="0,0,4.6,0,4.6" 
class="s6_239"
>) / (</text>

<text 
x="290" 
y="817" 
class="s7_239"
>total_spams</text>

<text 
x="385" 
y="817" 
class="s6_239"
>+</text>

<text 
x="401" 
y="817" 
class="s12_239"
>2</text>

<text 
x="416" 
y="817" 
class="s6_239"
>*</text>

<text 
x="432" 
y="817" 
class="s7_239"
>k</text>

<text 
x="440" 
y="817" 
class="s6_239"
>),</text>

<text 
x="179" 
y="832" 
class="s6_239"
>(</text>

<text 
x="187" 
y="832" 
class="s7_239"
>non_spam</text>

<text 
x="258" 
y="832" 
class="s6_239"
>+</text>

<text 
x="274" 
y="832" 
class="s7_239"
>k</text>

<text 
x="282" 
y="832" 
dx="0,0,4.6,0,4.6" 
class="s6_239"
>) / (</text>

<text 
x="322" 
y="832" 
class="s7_239"
>total_non_spams</text>

<text 
x="448" 
y="832" 
class="s6_239"
>+</text>

<text 
x="464" 
y="832" 
class="s12_239"
>2</text>

<text 
x="480" 
y="832" 
class="s6_239"
>*</text>

<text 
x="495" 
y="832" 
class="s7_239"
>k</text>

<text 
x="503" 
y="832" 
class="s6_239"
>))</text>

<text 
x="179" 
y="848" 
class="s4_239"
>for</text>

<text 
x="211" 
y="848" 
class="s7_239"
>w</text>

<text 
x="219" 
y="848" 
dx="0,0,4.6" 
class="s6_239"
>, (</text>

<text 
x="242" 
y="848" 
class="s7_239"
>spam</text>

<text 
x="274" 
y="848" 
class="s6_239"
>,</text>

<text 
x="290" 
y="848" 
class="s7_239"
>non_spam</text>

<text 
x="353" 
y="848" 
class="s6_239"
>)</text>

<text 
x="369" 
y="848" 
class="s13_239"
>in</text>

<text 
x="393" 
y="848" 
class="s7_239"
>counts</text>

<text 
x="440" 
y="848" 
class="s6_239"
>.</text>

<text 
x="448" 
y="848" 
class="s7_239"
>iteritems</text>

<text 
x="519" 
y="848" 
class="s6_239"
>()]</text>

<text 
x="55" 
y="901" 
class="s2_239"
>The last piece is to use these word probabilities (and our Naive Bayes assumptions) to</text>

<text 
x="55" 
y="928" 
class="s2_239"
>assign probabilities to messages:</text>

<text 
x="76" 
y="973" 
class="s4_239"
>def</text>

<text 
x="108" 
y="973" 
class="s5_239"
>spam_probability</text>

<text 
x="235" 
y="973" 
class="s6_239"
>(</text>

<text 
x="242" 
y="973" 
class="s7_239"
>word_probs</text>

<text 
x="322" 
y="973" 
class="s6_239"
>,</text>

<text 
x="337" 
y="973" 
class="s7_239"
>message</text>

<text 
x="393" 
y="973" 
class="s6_239"
>):</text>

<text 
x="108" 
y="989" 
class="s7_239"
>message_words</text>

<text 
x="219" 
y="989" 
class="s6_239"
>=</text>

<text 
x="235" 
y="989" 
class="s7_239"
>tokenize</text>

<text 
x="298" 
y="989" 
class="s6_239"
>(</text>

<text 
x="306" 
y="989" 
class="s7_239"
>message</text>

<text 
x="361" 
y="989" 
class="s6_239"
>)</text>

<text 
x="108" 
y="1004" 
class="s7_239"
>log_prob_if_spam</text>

<text 
x="242" 
y="1004" 
class="s6_239"
>=</text>

<text 
x="258" 
y="1004" 
class="s7_239"
>log_prob_if_not_spam</text>

<text 
x="424" 
y="1004" 
class="s6_239"
>=</text>

<text 
x="440" 
y="1004" 
class="s12_239"
>0.0</text>

<text 
x="108" 
y="1035" 
dx="0,0,4.6,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,4.6,0,0,0,0,4.6,0,0,0,0,4.6,0,0,4.6,0,0,0,4.6,0,0,0,0,0,0,0,0,0" 
class="s8_239"
># iterate through each word in our vocabulary</text>

<text 
x="108" 
y="1050" 
class="s4_239"
>for</text>

<text 
x="140" 
y="1050" 
class="s7_239"
>word</text>

<text 
x="171" 
y="1050" 
class="s6_239"
>,</text>

<text 
x="187" 
y="1050" 
class="s7_239"
>prob_if_spam</text>

<text 
x="282" 
y="1050" 
class="s6_239"
>,</text>

<text 
x="298" 
y="1050" 
class="s7_239"
>prob_if_not_spam</text>

<text 
x="432" 
y="1050" 
class="s13_239"
>in</text>

<text 
x="456" 
y="1050" 
class="s7_239"
>word_probs</text>

<text 
x="535" 
y="1050" 
class="s6_239"
>:</text>

<text 
x="140" 
y="1081" 
dx="0,0,4.6,0,0,4.6,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,4.6,0,0,4.6,0,0,0,4.6,0,0,0,0,0,0,0" 
class="s8_239"
># if *word* appears in the message,</text>

<text 
x="140" 
y="1096" 
dx="0,0,4.6,0,0,0,4.6,0,0,0,4.6,0,0,0,4.6,0,0,0,0,0,0,0,0,0,0,0,4.6,0,0,4.6,0,0,0,0,0,0,4.6,0" 
class="s8_239"
># add the log probability of seeing it</text>

<text 
x="140" 
y="1112" 
class="s4_239"
>if</text>

<text 
x="163" 
y="1112" 
class="s7_239"
>word</text>

<text 
x="203" 
y="1112" 
class="s13_239"
>in</text>

<text 
x="227" 
y="1112" 
class="s7_239"
>message_words</text>

<text 
x="329" 
y="1112" 
class="s6_239"
>:</text>

<text 
x="171" 
y="1127" 
class="s7_239"
>log_prob_if_spam</text>

<text 
x="306" 
y="1127" 
class="s6_239"
>+=</text>

<text 
x="329" 
y="1127" 
class="s7_239"
>math</text>

<text 
x="361" 
y="1127" 
class="s6_239"
>.</text>

<text 
x="369" 
y="1127" 
class="s7_239"
>log</text>

<text 
x="393" 
y="1127" 
class="s6_239"
>(</text>

<text 
x="401" 
y="1127" 
class="s7_239"
>prob_if_spam</text>

<text 
x="495" 
y="1127" 
class="s6_239"
>)</text>

<text 
x="171" 
y="1143" 
class="s7_239"
>log_prob_if_not_spam</text>

<text 
x="337" 
y="1143" 
class="s6_239"
>+=</text>

<text 
x="361" 
y="1143" 
class="s7_239"
>math</text>

<text 
x="393" 
y="1143" 
class="s6_239"
>.</text>

<text 
x="401" 
y="1143" 
class="s7_239"
>log</text>

<text 
x="424" 
y="1143" 
class="s6_239"
>(</text>

<text 
x="432" 
y="1143" 
class="s7_239"
>prob_if_not_spam</text>

<text 
x="559" 
y="1143" 
class="s6_239"
>)</text>

<text 
x="140" 
y="1173" 
dx="0,0,4.6,0,0,4.6,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,4.6,0,0,4.6,0,0,0,4.6,0,0,0,0,0,0" 
class="s8_239"
># if *word* doesn't appear in the message</text>

<text 
x="140" 
y="1189" 
dx="0,0,4.6,0,0,0,4.6,0,0,0,4.6,0,0,0,4.6,0,0,0,0,0,0,0,0,0,0,0,4.6,0,0,4.6,0,0,0,0,0,4.6,0,0,0,0,0,0,4.6,0" 
class="s8_239"
># add the log probability of _not_ seeing it</text>

<text 
x="140" 
y="1204" 
dx="0,0,4.6,0,0,0,0,0,4.6,0,0,4.6,0,0,0,0,0,4.6,0,4.6,0,0,0,0,0,0,0,0,0,0,0,4.6,0,0,4.6,0,0,0,0,0,0,4.6,0,0" 
class="s8_239"
># which is log(1 - probability of seeing it)</text>

<text 
x="140" 
y="1220" 
class="s4_239"
>else</text>

<text 
x="171" 
y="1220" 
class="s6_239"
>:</text>



<!-- Any embedded fonts defined here -->
<style type="text/css" ><![CDATA[

@font-face {
	font-family: LiberationMono-Bold_1w;
	src: url("fonts/LiberationMono-Bold_1w.woff") format("woff");
}

@font-face {
	font-family: LiberationMono_1q;
	src: url("fonts/LiberationMono_1q.woff") format("woff");
}

@font-face {
	font-family: LiberationMono-Italic_10;
	src: url("fonts/LiberationMono-Italic_10.woff") format("woff");
}

@font-face {
	font-family: LiberationSerif-Bold_b;
	src: url("fonts/LiberationSerif-Bold_b.woff") format("woff");
}

@font-face {
	font-family: LiberationSerif_e;
	src: url("fonts/LiberationSerif_e.woff") format("woff");
}

]]></style>

</svg>
