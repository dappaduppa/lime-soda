<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">


<!-- Page 208 -->
<svg x="0" y="0" width="909" height="1286" viewBox="0 0 909 1286" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
style="display: block;margin-left: auto;margin-right: auto;">
<defs>

<style type="text/css"><![CDATA[


.s1_208{
font-size: 22.01px;
font-family: LiberationSerif_e;
fill: #000000;
}
.s2_208{
font-size: 13.20px;
font-family: LiberationMono-Bold_1w;
fill: #006699;
}
.s3_208{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #CC00FF;
}
.s4_208{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #000000;
}
.s5_208{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #000088;
}
.s6_208{
font-size: 13.20px;
font-family: LiberationMono-Italic_10;
fill: #CC3300;
}
.s7_208{
font-size: 13.20px;
font-family: LiberationMono-Bold_1w;
fill: #000000;
}
.s8_208{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #FF6600;
}
.s9_208{
font-size: 17.60px;
font-family: LiberationMono_1q;
fill: #000000;
}
.s10_208{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #336666;
}
.s11_208{
font-size: 13.20px;
font-family: LiberationMono-Italic_10;
fill: #0099FF;
}
.s12_208{
font-size: 22.01px;
font-family: LiberationSerif-Italic_l;
fill: #000000;
}

]]></style>

</defs>
<path d="M0,0
L0,1286
L909,1286
L909,0 Z " 
fill="#FFFFFF" stroke="none" />
<text 
x="55" 
y="74" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0.4,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_208"
>the data they were trained on. So how do we make sure our models aren’t too complex?</text>

<text 
x="55" 
y="102" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_208"
>The most fundamental approach involves using different data to train the model and to test</text>

<text 
x="55" 
y="129" 
class="s1_208"
>the model.</text>

<text 
x="55" 
y="168" 
class="s1_208"
>The simplest way to do this is to split your data set, so that (for example) two-thirds of it is</text>

<text 
x="55" 
y="195" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_208"
>used to train the model, after which we measure the model’s performance on the</text>

<text 
x="55" 
y="223" 
class="s1_208"
>remaining third:</text>

<text 
x="76" 
y="268" 
class="s2_208"
>def</text>

<text 
x="108" 
y="268" 
class="s3_208"
>split_data</text>

<text 
x="187" 
y="268" 
class="s4_208"
>(</text>

<text 
x="195" 
y="268" 
class="s5_208"
>data</text>

<text 
x="227" 
y="268" 
class="s4_208"
>,</text>

<text 
x="242" 
y="268" 
class="s5_208"
>prob</text>

<text 
x="274" 
y="268" 
class="s4_208"
>):</text>

<text 
x="108" 
y="283" 
dx="0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,4.6,0,0,0,0,4.6,0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,4.6,0,4.6,0,4.6,0,0,0,0,0,0,0" 
class="s6_208"
>"""split data into fractions [prob, 1 - prob]"""</text>

<text 
x="108" 
y="299" 
class="s5_208"
>results</text>

<text 
x="171" 
y="299" 
dx="0,0,4.6,0,0,0,4.6,0" 
class="s4_208"
>= [], []</text>

<text 
x="108" 
y="314" 
class="s2_208"
>for</text>

<text 
x="140" 
y="314" 
class="s5_208"
>row</text>

<text 
x="171" 
y="314" 
class="s7_208"
>in</text>

<text 
x="195" 
y="314" 
class="s5_208"
>data</text>

<text 
x="227" 
y="314" 
class="s4_208"
>:</text>

<text 
x="140" 
y="330" 
class="s5_208"
>results</text>

<text 
x="195" 
y="330" 
class="s4_208"
>[</text>

<text 
x="203" 
y="330" 
class="s8_208"
>0</text>

<text 
x="219" 
y="330" 
class="s2_208"
>if</text>

<text 
x="242" 
y="330" 
class="s5_208"
>random</text>

<text 
x="290" 
y="330" 
class="s4_208"
>.</text>

<text 
x="298" 
y="330" 
class="s5_208"
>random</text>

<text 
x="345" 
y="330" 
dx="0,0,0,4.6" 
class="s4_208"
>() &lt;</text>

<text 
x="385" 
y="330" 
class="s5_208"
>prob</text>

<text 
x="424" 
y="330" 
class="s2_208"
>else</text>

<text 
x="464" 
y="330" 
class="s8_208"
>1</text>

<text 
x="472" 
y="330" 
class="s4_208"
>].</text>

<text 
x="487" 
y="330" 
class="s5_208"
>append</text>

<text 
x="535" 
y="330" 
class="s4_208"
>(</text>

<text 
x="543" 
y="330" 
class="s5_208"
>row</text>

<text 
x="567" 
y="330" 
class="s4_208"
>)</text>

<text 
x="108" 
y="345" 
class="s2_208"
>return</text>

<text 
x="163" 
y="345" 
class="s5_208"
>results</text>

<text 
x="55" 
y="398" 
class="s1_208"
>Often, we’ll have a matrix</text>

<text 
x="291" 
y="398" 
class="s9_208"
>x</text>

<text 
x="307" 
y="398" 
class="s1_208"
>of input variables and a vector</text>

<text 
x="580" 
y="398" 
class="s9_208"
>y</text>

<text 
x="596" 
y="398" 
class="s1_208"
>of output variables. In that</text>

<text 
x="55" 
y="428" 
class="s1_208"
>case, we need to make sure to put corresponding values together in either the training data</text>

<text 
x="55" 
y="455" 
class="s1_208"
>or the test data:</text>

<text 
x="76" 
y="500" 
class="s2_208"
>def</text>

<text 
x="108" 
y="500" 
class="s3_208"
>train_test_split</text>

<text 
x="235" 
y="500" 
class="s4_208"
>(</text>

<text 
x="242" 
y="500" 
class="s5_208"
>x</text>

<text 
x="250" 
y="500" 
class="s4_208"
>,</text>

<text 
x="266" 
y="500" 
class="s5_208"
>y</text>

<text 
x="274" 
y="500" 
class="s4_208"
>,</text>

<text 
x="290" 
y="500" 
class="s5_208"
>test_pct</text>

<text 
x="353" 
y="500" 
class="s4_208"
>):</text>

<text 
x="108" 
y="516" 
class="s5_208"
>data</text>

<text 
x="148" 
y="516" 
class="s4_208"
>=</text>

<text 
x="163" 
y="516" 
class="s10_208"
>zip</text>

<text 
x="187" 
y="516" 
class="s4_208"
>(</text>

<text 
x="195" 
y="516" 
class="s5_208"
>x</text>

<text 
x="203" 
y="516" 
class="s4_208"
>,</text>

<text 
x="219" 
y="516" 
class="s5_208"
>y</text>

<text 
x="227" 
y="516" 
class="s4_208"
>)</text>

<text 
x="472" 
y="516" 
dx="0,0,4.6,0,0,0,0,4.6,0,0,0,0,0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,0" 
class="s11_208"
># pair corresponding values</text>

<text 
x="108" 
y="531" 
class="s5_208"
>train</text>

<text 
x="148" 
y="531" 
class="s4_208"
>,</text>

<text 
x="163" 
y="531" 
class="s5_208"
>test</text>

<text 
x="203" 
y="531" 
class="s4_208"
>=</text>

<text 
x="219" 
y="531" 
class="s5_208"
>split_data</text>

<text 
x="298" 
y="531" 
class="s4_208"
>(</text>

<text 
x="306" 
y="531" 
class="s5_208"
>data</text>

<text 
x="337" 
y="531" 
class="s4_208"
>,</text>

<text 
x="353" 
y="531" 
class="s8_208"
>1</text>

<text 
x="369" 
y="531" 
class="s4_208"
>-</text>

<text 
x="385" 
y="531" 
class="s5_208"
>test_pct</text>

<text 
x="448" 
y="531" 
class="s4_208"
>)</text>

<text 
x="472" 
y="531" 
dx="0,0,4.6,0,0,0,0,0,4.6,0,0,0,4.6,0,0,0,0,4.6,0,0,0,4.6,0,0,4.6,0,0,0,0" 
class="s11_208"
># split the data set of pairs</text>

<text 
x="108" 
y="546" 
class="s5_208"
>x_train</text>

<text 
x="163" 
y="546" 
class="s4_208"
>,</text>

<text 
x="179" 
y="546" 
class="s5_208"
>y_train</text>

<text 
x="242" 
y="546" 
class="s4_208"
>=</text>

<text 
x="258" 
y="546" 
class="s10_208"
>zip</text>

<text 
x="282" 
y="546" 
class="s4_208"
>(*</text>

<text 
x="298" 
y="546" 
class="s5_208"
>train</text>

<text 
x="337" 
y="546" 
class="s4_208"
>)</text>

<text 
x="472" 
y="546" 
dx="0,0,4.6,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,4.6,0,0,0,0" 
class="s11_208"
># magical un-zip trick</text>

<text 
x="108" 
y="562" 
class="s5_208"
>x_test</text>

<text 
x="156" 
y="562" 
class="s4_208"
>,</text>

<text 
x="171" 
y="562" 
class="s5_208"
>y_test</text>

<text 
x="227" 
y="562" 
class="s4_208"
>=</text>

<text 
x="242" 
y="562" 
class="s10_208"
>zip</text>

<text 
x="266" 
y="562" 
class="s4_208"
>(*</text>

<text 
x="282" 
y="562" 
class="s5_208"
>test</text>

<text 
x="314" 
y="562" 
class="s4_208"
>)</text>

<text 
x="108" 
y="577" 
class="s2_208"
>return</text>

<text 
x="163" 
y="577" 
class="s5_208"
>x_train</text>

<text 
x="219" 
y="577" 
class="s4_208"
>,</text>

<text 
x="235" 
y="577" 
class="s5_208"
>x_test</text>

<text 
x="282" 
y="577" 
class="s4_208"
>,</text>

<text 
x="298" 
y="577" 
class="s5_208"
>y_train</text>

<text 
x="353" 
y="577" 
class="s4_208"
>,</text>

<text 
x="369" 
y="577" 
class="s5_208"
>y_test</text>

<text 
x="55" 
y="630" 
class="s1_208"
>so that you might do something like:</text>

<text 
x="76" 
y="675" 
class="s5_208"
>model</text>

<text 
x="124" 
y="675" 
class="s4_208"
>=</text>

<text 
x="140" 
y="675" 
class="s5_208"
>SomeKindOfModel</text>

<text 
x="258" 
y="675" 
class="s4_208"
>()</text>

<text 
x="76" 
y="690" 
class="s5_208"
>x_train</text>

<text 
x="132" 
y="690" 
class="s4_208"
>,</text>

<text 
x="148" 
y="690" 
class="s5_208"
>x_test</text>

<text 
x="195" 
y="690" 
class="s4_208"
>,</text>

<text 
x="211" 
y="690" 
class="s5_208"
>y_train</text>

<text 
x="266" 
y="690" 
class="s4_208"
>,</text>

<text 
x="282" 
y="690" 
class="s5_208"
>y_test</text>

<text 
x="337" 
y="690" 
class="s4_208"
>=</text>

<text 
x="353" 
y="690" 
class="s5_208"
>train_test_split</text>

<text 
x="480" 
y="690" 
class="s4_208"
>(</text>

<text 
x="487" 
y="690" 
class="s5_208"
>xs</text>

<text 
x="503" 
y="690" 
class="s4_208"
>,</text>

<text 
x="519" 
y="690" 
class="s5_208"
>ys</text>

<text 
x="535" 
y="690" 
class="s4_208"
>,</text>

<text 
x="551" 
y="690" 
class="s8_208"
>0.33</text>

<text 
x="582" 
y="690" 
class="s4_208"
>)</text>

<text 
x="76" 
y="706" 
class="s5_208"
>model</text>

<text 
x="116" 
y="706" 
class="s4_208"
>.</text>

<text 
x="124" 
y="706" 
class="s5_208"
>train</text>

<text 
x="163" 
y="706" 
class="s4_208"
>(</text>

<text 
x="171" 
y="706" 
class="s5_208"
>x_train</text>

<text 
x="227" 
y="706" 
class="s4_208"
>,</text>

<text 
x="242" 
y="706" 
class="s5_208"
>y_train</text>

<text 
x="298" 
y="706" 
class="s4_208"
>)</text>

<text 
x="76" 
y="721" 
class="s5_208"
>performance</text>

<text 
x="171" 
y="721" 
class="s4_208"
>=</text>

<text 
x="187" 
y="721" 
class="s5_208"
>model</text>

<text 
x="227" 
y="721" 
class="s4_208"
>.</text>

<text 
x="235" 
y="721" 
class="s5_208"
>test</text>

<text 
x="266" 
y="721" 
class="s4_208"
>(</text>

<text 
x="274" 
y="721" 
class="s5_208"
>x_test</text>

<text 
x="322" 
y="721" 
class="s4_208"
>,</text>

<text 
x="337" 
y="721" 
class="s5_208"
>y_test</text>

<text 
x="385" 
y="721" 
class="s4_208"
>)</text>

<text 
x="55" 
y="774" 
class="s1_208"
>If the model was overfit to the training data, then it will hopefully perform really poorly</text>

<text 
x="55" 
y="802" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0.4,0,0,0,0,0,0,0,-1.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_208"
>on the (completely separate) test data. Said differently, if it performs well on the test data,</text>

<text 
x="55" 
y="829" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.2" 
class="s1_208"
>then you can be more confident that it’s</text>

<text 
x="409" 
y="829" 
class="s12_208"
>fitting</text>

<text 
x="467" 
y="829" 
class="s1_208"
>rather than</text>

<text 
x="567" 
y="829" 
class="s12_208"
>overfitting</text>

<text 
x="658" 
y="829" 
class="s1_208"
>.</text>

<text 
x="55" 
y="868" 
dx="0,0,0,0,0,0,0,-0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_208"
>However, there are a couple of ways this can go wrong.</text>

<text 
x="55" 
y="906" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0.4,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_208"
>The first is if there are common patterns in the test and train data that wouldn’t generalize</text>

<text 
x="55" 
y="934" 
dx="0,0,0,0,0,0,0,0,-0.4,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_208"
>to a larger data set.</text>

<text 
x="55" 
y="972" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_208"
>For example, imagine that your data set consists of user activity, one row per user per</text>

<text 
x="55" 
y="1000" 
class="s1_208"
>week. In such a case, most users will appear in both the training data and the test data, and</text>

<text 
x="55" 
y="1027" 
class="s1_208"
>certain models might learn to</text>

<text 
x="318" 
y="1027" 
class="s12_208"
>identify</text>

<text 
x="389" 
y="1027" 
class="s1_208"
>users rather than discover relationships involving</text>

<text 
x="55" 
y="1055" 
class="s12_208"
>attributes</text>

<text 
x="139" 
y="1055" 
dx="0,0,0,0,0,0,0,0,0,0,0,-0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_208"
>. This isn’t a huge worry, although it did happen to me once.</text>

<text 
x="55" 
y="1093" 
dx="0,0,-1.2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_208"
>A bigger problem is if you use the test/train split not just to judge a model but also to</text>

<text 
x="55" 
y="1121" 
class="s12_208"
>choose</text>

<text 
x="121" 
y="1121" 
class="s1_208"
>from among many models. In that case, although each individual model may not</text>

<text 
x="55" 
y="1148" 
class="s1_208"
>be overfit, the “choose a model that performs best on the test set” is a meta-training that</text>

<text 
x="55" 
y="1176" 
class="s1_208"
>makes the test set function as a second training set. (Of course the model that performed</text>

<text 
x="55" 
y="1203" 
class="s1_208"
>best on the test set is going to perform well on the test set.)</text>



<!-- Any embedded fonts defined here -->
<style type="text/css" ><![CDATA[

@font-face {
	font-family: LiberationMono-Bold_1w;
	src: url("fonts/LiberationMono-Bold_1w.woff") format("woff");
}

@font-face {
	font-family: LiberationSerif-Italic_l;
	src: url("fonts/LiberationSerif-Italic_l.woff") format("woff");
}

@font-face {
	font-family: LiberationMono_1q;
	src: url("fonts/LiberationMono_1q.woff") format("woff");
}

@font-face {
	font-family: LiberationMono-Italic_10;
	src: url("fonts/LiberationMono-Italic_10.woff") format("woff");
}

@font-face {
	font-family: LiberationSerif_e;
	src: url("fonts/LiberationSerif_e.woff") format("woff");
}

]]></style>

</svg>
