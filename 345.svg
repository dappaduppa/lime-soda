<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">


<!-- Page 345 -->
<svg x="0" y="0" width="909" height="1286" viewBox="0 0 909 1286" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
style="display: block;margin-left: auto;margin-right: auto;">
<defs>

<style type="text/css"><![CDATA[


.s1_345{
font-size: 22.01px;
font-family: LiberationSerif_e;
fill: #000000;
}
.s2_345{
font-size: 17.60px;
font-family: LiberationMono_1q;
fill: #000000;
}
.s3_345{
font-size: 13.20px;
font-family: LiberationMono-Bold_1w;
fill: #006699;
}
.s4_345{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #CC00FF;
}
.s5_345{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #000000;
}
.s6_345{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #000088;
}
.s7_345{
font-size: 13.20px;
font-family: LiberationMono-Italic_10;
fill: #CC3300;
}
.s8_345{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #336666;
}
.s9_345{
font-size: 13.20px;
font-family: LiberationMono-Italic_10;
fill: #0099FF;
}
.s10_345{
font-size: 13.20px;
font-family: LiberationMono-Bold_1w;
fill: #000000;
}
.s11_345{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #FF6600;
}
.s12_345{
font-size: 13.20px;
font-family: LiberationMono_1q;
fill: #CC3300;
}

]]></style>

</defs>
<path d="M0,0
L0,1286
L909,1286
L909,0 Z " 
fill="#FFFFFF" stroke="none" />
<text 
x="55" 
y="74" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_345"
>the words on which they put the heaviest weight. We just have to somehow generate the</text>

<text 
x="55" 
y="102" 
class="s2_345"
>document_topics</text>

<text 
x="213" 
y="102" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.4" 
class="s1_345"
>. This is where Gibbs sampling comes into play.</text>

<text 
x="55" 
y="143" 
dx="0,-1.8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_345"
>We start by assigning every word in every document a topic completely at random. Now</text>

<text 
x="55" 
y="170" 
class="s1_345"
>we go through each document one word at a time. For that word and document, we</text>

<text 
x="55" 
y="198" 
class="s1_345"
>construct weights for each topic that depend on the (current) distribution of topics in that</text>

<text 
x="55" 
y="225" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_345"
>document and the (current) distribution of words for that topic. We then use those weights</text>

<text 
x="55" 
y="253" 
class="s1_345"
>to sample a new topic for that word. If we iterate this process many times, we will end up</text>

<text 
x="55" 
y="280" 
class="s1_345"
>with a joint sample from the topic-word distribution and the document-topic distribution.</text>

<text 
x="55" 
y="319" 
dx="0,-1.6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_345"
>To start with, we’ll need a function to randomly choose an index based on an arbitrary set</text>

<text 
x="55" 
y="346" 
class="s1_345"
>of weights:</text>

<text 
x="76" 
y="391" 
class="s3_345"
>def</text>

<text 
x="108" 
y="391" 
class="s4_345"
>sample_from</text>

<text 
x="195" 
y="391" 
class="s5_345"
>(</text>

<text 
x="203" 
y="391" 
class="s6_345"
>weights</text>

<text 
x="258" 
y="391" 
class="s5_345"
>):</text>

<text 
x="108" 
y="407" 
dx="0,0,0,0,0,0,0,0,0,0,0,4.6,0,4.6,0,0,0,0,4.6,0,0,0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0,0,0,4.6,0,4.6,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s7_345"
>"""returns i with probability weights[i] / sum(weights)"""</text>

<text 
x="108" 
y="422" 
class="s6_345"
>total</text>

<text 
x="156" 
y="422" 
class="s5_345"
>=</text>

<text 
x="171" 
y="422" 
class="s8_345"
>sum</text>

<text 
x="195" 
y="422" 
class="s5_345"
>(</text>

<text 
x="203" 
y="422" 
class="s6_345"
>weights</text>

<text 
x="258" 
y="422" 
class="s5_345"
>)</text>

<text 
x="108" 
y="437" 
class="s6_345"
>rnd</text>

<text 
x="140" 
y="437" 
class="s5_345"
>=</text>

<text 
x="156" 
y="437" 
class="s6_345"
>total</text>

<text 
x="203" 
y="437" 
class="s5_345"
>*</text>

<text 
x="219" 
y="437" 
class="s6_345"
>random</text>

<text 
x="266" 
y="437" 
class="s5_345"
>.</text>

<text 
x="274" 
y="437" 
class="s6_345"
>random</text>

<text 
x="322" 
y="437" 
class="s5_345"
>()</text>

<text 
x="385" 
y="437" 
dx="0,0,4.6,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,4.6,0,4.6,0,0,0,4.6,0,0,0,0" 
class="s9_345"
># uniform between 0 and total</text>

<text 
x="108" 
y="453" 
class="s3_345"
>for</text>

<text 
x="140" 
y="453" 
class="s6_345"
>i</text>

<text 
x="148" 
y="453" 
class="s5_345"
>,</text>

<text 
x="163" 
y="453" 
class="s6_345"
>w</text>

<text 
x="179" 
y="453" 
class="s10_345"
>in</text>

<text 
x="203" 
y="453" 
class="s8_345"
>enumerate</text>

<text 
x="274" 
y="453" 
class="s5_345"
>(</text>

<text 
x="282" 
y="453" 
class="s6_345"
>weights</text>

<text 
x="337" 
y="453" 
class="s5_345"
>):</text>

<text 
x="140" 
y="468" 
class="s6_345"
>rnd</text>

<text 
x="171" 
y="468" 
class="s5_345"
>-=</text>

<text 
x="195" 
y="468" 
class="s6_345"
>w</text>

<text 
x="385" 
y="468" 
dx="0,0,4.6,0,0,0,0,0,0,4.6,0,0,0,4.6,0,0,0,0,0,0,0,0,4.6,0,4.6,0,0,0,0,4.6,0,0,0" 
class="s9_345"
># return the smallest i such that</text>

<text 
x="140" 
y="484" 
class="s3_345"
>if</text>

<text 
x="163" 
y="484" 
class="s6_345"
>rnd</text>

<text 
x="195" 
y="484" 
class="s5_345"
>&lt;=</text>

<text 
x="219" 
y="484" 
class="s11_345"
>0</text>

<text 
x="227" 
y="484" 
class="s5_345"
>:</text>

<text 
x="242" 
y="484" 
class="s3_345"
>return</text>

<text 
x="298" 
y="484" 
class="s6_345"
>i</text>

<text 
x="385" 
y="484" 
dx="0,0,4.6,0,0,0,0,0,0,0,0,0,0,4.6,0,4.6,0,0,0,4.6,0,4.6,0,0,0,0,0,0,0,0,0,0,4.6,0,0,4.6,0,0" 
class="s9_345"
># weights[0] + ... + weights[i] &gt;= rnd</text>

<text 
x="55" 
y="536" 
class="s1_345"
>For instance, if you give it weights</text>

<text 
x="366" 
y="536" 
dx="0,0,0,0,6.1,0,0,6.1,0" 
class="s2_345"
>[1, 1, 3]</text>

<text 
x="466" 
y="536" 
class="s1_345"
>then one-fifth of the time it will return 0,</text>

<text 
x="55" 
y="566" 
class="s1_345"
>one-fifth of the time it will return 1, and three-fifths of the time it will return 2.</text>

<text 
x="55" 
y="605" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_345"
>Our documents are our users’ interests, which look like:</text>

<text 
x="76" 
y="650" 
class="s6_345"
>documents</text>

<text 
x="156" 
y="650" 
dx="0,0,4.6" 
class="s5_345"
>= [</text>

<text 
x="108" 
y="665" 
class="s5_345"
>[</text>

<text 
x="116" 
y="665" 
class="s12_345"
>"Hadoop"</text>

<text 
x="179" 
y="665" 
class="s5_345"
>,</text>

<text 
x="195" 
y="665" 
dx="0,0,0,0,0,4.6,0,0,0,0" 
class="s12_345"
>"Big Data"</text>

<text 
x="274" 
y="665" 
class="s5_345"
>,</text>

<text 
x="290" 
y="665" 
class="s12_345"
>"HBase"</text>

<text 
x="345" 
y="665" 
class="s5_345"
>,</text>

<text 
x="361" 
y="665" 
class="s12_345"
>"Java"</text>

<text 
x="408" 
y="665" 
class="s5_345"
>,</text>

<text 
x="424" 
y="665" 
class="s12_345"
>"Spark"</text>

<text 
x="480" 
y="665" 
class="s5_345"
>,</text>

<text 
x="495" 
y="665" 
class="s12_345"
>"Storm"</text>

<text 
x="551" 
y="665" 
class="s5_345"
>,</text>

<text 
x="567" 
y="665" 
class="s12_345"
>"Cassandra"</text>

<text 
x="653" 
y="665" 
class="s5_345"
>],</text>

<text 
x="108" 
y="681" 
class="s5_345"
>[</text>

<text 
x="116" 
y="681" 
class="s12_345"
>"NoSQL"</text>

<text 
x="171" 
y="681" 
class="s5_345"
>,</text>

<text 
x="187" 
y="681" 
class="s12_345"
>"MongoDB"</text>

<text 
x="258" 
y="681" 
class="s5_345"
>,</text>

<text 
x="274" 
y="681" 
class="s12_345"
>"Cassandra"</text>

<text 
x="361" 
y="681" 
class="s5_345"
>,</text>

<text 
x="377" 
y="681" 
class="s12_345"
>"HBase"</text>

<text 
x="432" 
y="681" 
class="s5_345"
>,</text>

<text 
x="448" 
y="681" 
class="s12_345"
>"Postgres"</text>

<text 
x="527" 
y="681" 
class="s5_345"
>],</text>

<text 
x="108" 
y="696" 
class="s5_345"
>[</text>

<text 
x="116" 
y="696" 
class="s12_345"
>"Python"</text>

<text 
x="179" 
y="696" 
class="s5_345"
>,</text>

<text 
x="195" 
y="696" 
class="s12_345"
>"scikit-learn"</text>

<text 
x="306" 
y="696" 
class="s5_345"
>,</text>

<text 
x="322" 
y="696" 
class="s12_345"
>"scipy"</text>

<text 
x="377" 
y="696" 
class="s5_345"
>,</text>

<text 
x="393" 
y="696" 
class="s12_345"
>"numpy"</text>

<text 
x="448" 
y="696" 
class="s5_345"
>,</text>

<text 
x="464" 
y="696" 
class="s12_345"
>"statsmodels"</text>

<text 
x="567" 
y="696" 
class="s5_345"
>,</text>

<text 
x="582" 
y="696" 
class="s12_345"
>"pandas"</text>

<text 
x="646" 
y="696" 
class="s5_345"
>],</text>

<text 
x="108" 
y="711" 
class="s5_345"
>[</text>

<text 
x="116" 
y="711" 
class="s12_345"
>"R"</text>

<text 
x="140" 
y="711" 
class="s5_345"
>,</text>

<text 
x="156" 
y="711" 
class="s12_345"
>"Python"</text>

<text 
x="219" 
y="711" 
class="s5_345"
>,</text>

<text 
x="235" 
y="711" 
class="s12_345"
>"statistics"</text>

<text 
x="329" 
y="711" 
class="s5_345"
>,</text>

<text 
x="345" 
y="711" 
class="s12_345"
>"regression"</text>

<text 
x="440" 
y="711" 
class="s5_345"
>,</text>

<text 
x="456" 
y="711" 
class="s12_345"
>"probability"</text>

<text 
x="559" 
y="711" 
class="s5_345"
>],</text>

<text 
x="108" 
y="727" 
class="s5_345"
>[</text>

<text 
x="116" 
y="727" 
dx="0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0" 
class="s12_345"
>"machine learning"</text>

<text 
x="258" 
y="727" 
class="s5_345"
>,</text>

<text 
x="274" 
y="727" 
class="s12_345"
>"regression"</text>

<text 
x="369" 
y="727" 
class="s5_345"
>,</text>

<text 
x="385" 
y="727" 
dx="0,0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,0" 
class="s12_345"
>"decision trees"</text>

<text 
x="511" 
y="727" 
class="s5_345"
>,</text>

<text 
x="527" 
y="727" 
class="s12_345"
>"libsvm"</text>

<text 
x="590" 
y="727" 
class="s5_345"
>],</text>

<text 
x="108" 
y="742" 
class="s5_345"
>[</text>

<text 
x="116" 
y="742" 
class="s12_345"
>"Python"</text>

<text 
x="179" 
y="742" 
class="s5_345"
>,</text>

<text 
x="195" 
y="742" 
class="s12_345"
>"R"</text>

<text 
x="219" 
y="742" 
class="s5_345"
>,</text>

<text 
x="235" 
y="742" 
class="s12_345"
>"Java"</text>

<text 
x="282" 
y="742" 
class="s5_345"
>,</text>

<text 
x="298" 
y="742" 
class="s12_345"
>"C++"</text>

<text 
x="337" 
y="742" 
class="s5_345"
>,</text>

<text 
x="353" 
y="742" 
class="s12_345"
>"Haskell"</text>

<text 
x="424" 
y="742" 
class="s5_345"
>,</text>

<text 
x="440" 
y="742" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0,0" 
class="s12_345"
>"programming languages"</text>

<text 
x="622" 
y="742" 
class="s5_345"
>],</text>

<text 
x="108" 
y="758" 
class="s5_345"
>[</text>

<text 
x="116" 
y="758" 
class="s12_345"
>"statistics"</text>

<text 
x="211" 
y="758" 
class="s5_345"
>,</text>

<text 
x="227" 
y="758" 
class="s12_345"
>"probability"</text>

<text 
x="329" 
y="758" 
class="s5_345"
>,</text>

<text 
x="345" 
y="758" 
class="s12_345"
>"mathematics"</text>

<text 
x="448" 
y="758" 
class="s5_345"
>,</text>

<text 
x="464" 
y="758" 
class="s12_345"
>"theory"</text>

<text 
x="527" 
y="758" 
class="s5_345"
>],</text>

<text 
x="108" 
y="773" 
class="s5_345"
>[</text>

<text 
x="116" 
y="773" 
dx="0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0" 
class="s12_345"
>"machine learning"</text>

<text 
x="258" 
y="773" 
class="s5_345"
>,</text>

<text 
x="274" 
y="773" 
class="s12_345"
>"scikit-learn"</text>

<text 
x="385" 
y="773" 
class="s5_345"
>,</text>

<text 
x="401" 
y="773" 
class="s12_345"
>"Mahout"</text>

<text 
x="464" 
y="773" 
class="s5_345"
>,</text>

<text 
x="480" 
y="773" 
dx="0,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0" 
class="s12_345"
>"neural networks"</text>

<text 
x="614" 
y="773" 
class="s5_345"
>],</text>

<text 
x="108" 
y="788" 
class="s5_345"
>[</text>

<text 
x="116" 
y="788" 
dx="0,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0" 
class="s12_345"
>"neural networks"</text>

<text 
x="250" 
y="788" 
class="s5_345"
>,</text>

<text 
x="266" 
y="788" 
dx="0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0" 
class="s12_345"
>"deep learning"</text>

<text 
x="385" 
y="788" 
class="s5_345"
>,</text>

<text 
x="401" 
y="788" 
dx="0,0,0,0,0,4.6,0,0,0,0" 
class="s12_345"
>"Big Data"</text>

<text 
x="480" 
y="788" 
class="s5_345"
>,</text>

<text 
x="495" 
y="788" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s12_345"
>"artificial intelligence"</text>

<text 
x="693" 
y="788" 
class="s5_345"
>],</text>

<text 
x="108" 
y="804" 
class="s5_345"
>[</text>

<text 
x="116" 
y="804" 
class="s12_345"
>"Hadoop"</text>

<text 
x="179" 
y="804" 
class="s5_345"
>,</text>

<text 
x="195" 
y="804" 
class="s12_345"
>"Java"</text>

<text 
x="242" 
y="804" 
class="s5_345"
>,</text>

<text 
x="258" 
y="804" 
class="s12_345"
>"MapReduce"</text>

<text 
x="345" 
y="804" 
class="s5_345"
>,</text>

<text 
x="361" 
y="804" 
dx="0,0,0,0,0,4.6,0,0,0,0" 
class="s12_345"
>"Big Data"</text>

<text 
x="440" 
y="804" 
class="s5_345"
>],</text>

<text 
x="108" 
y="819" 
class="s5_345"
>[</text>

<text 
x="116" 
y="819" 
class="s12_345"
>"statistics"</text>

<text 
x="211" 
y="819" 
class="s5_345"
>,</text>

<text 
x="227" 
y="819" 
class="s12_345"
>"R"</text>

<text 
x="250" 
y="819" 
class="s5_345"
>,</text>

<text 
x="266" 
y="819" 
class="s12_345"
>"statsmodels"</text>

<text 
x="369" 
y="819" 
class="s5_345"
>],</text>

<text 
x="108" 
y="835" 
class="s5_345"
>[</text>

<text 
x="116" 
y="835" 
class="s12_345"
>"C++"</text>

<text 
x="156" 
y="835" 
class="s5_345"
>,</text>

<text 
x="171" 
y="835" 
dx="0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0" 
class="s12_345"
>"deep learning"</text>

<text 
x="290" 
y="835" 
class="s5_345"
>,</text>

<text 
x="306" 
y="835" 
dx="0,0,0,0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s12_345"
>"artificial intelligence"</text>

<text 
x="503" 
y="835" 
class="s5_345"
>,</text>

<text 
x="519" 
y="835" 
class="s12_345"
>"probability"</text>

<text 
x="622" 
y="835" 
class="s5_345"
>],</text>

<text 
x="108" 
y="850" 
class="s5_345"
>[</text>

<text 
x="116" 
y="850" 
class="s12_345"
>"pandas"</text>

<text 
x="179" 
y="850" 
class="s5_345"
>,</text>

<text 
x="195" 
y="850" 
class="s12_345"
>"R"</text>

<text 
x="219" 
y="850" 
class="s5_345"
>,</text>

<text 
x="235" 
y="850" 
class="s12_345"
>"Python"</text>

<text 
x="298" 
y="850" 
class="s5_345"
>],</text>

<text 
x="108" 
y="865" 
class="s5_345"
>[</text>

<text 
x="116" 
y="865" 
class="s12_345"
>"databases"</text>

<text 
x="203" 
y="865" 
class="s5_345"
>,</text>

<text 
x="219" 
y="865" 
class="s12_345"
>"HBase"</text>

<text 
x="274" 
y="865" 
class="s5_345"
>,</text>

<text 
x="290" 
y="865" 
class="s12_345"
>"Postgres"</text>

<text 
x="369" 
y="865" 
class="s5_345"
>,</text>

<text 
x="385" 
y="865" 
class="s12_345"
>"MySQL"</text>

<text 
x="440" 
y="865" 
class="s5_345"
>,</text>

<text 
x="456" 
y="865" 
class="s12_345"
>"MongoDB"</text>

<text 
x="527" 
y="865" 
class="s5_345"
>],</text>

<text 
x="108" 
y="881" 
class="s5_345"
>[</text>

<text 
x="116" 
y="881" 
class="s12_345"
>"libsvm"</text>

<text 
x="179" 
y="881" 
class="s5_345"
>,</text>

<text 
x="195" 
y="881" 
class="s12_345"
>"regression"</text>

<text 
x="290" 
y="881" 
class="s5_345"
>,</text>

<text 
x="306" 
y="881" 
dx="0,0,0,0,0,0,0,0,0,4.6,0,0,0,0,0,0,4.6,0,0,0,0,0,0,0,0" 
class="s12_345"
>"support vector machines"</text>

<text 
x="503" 
y="881" 
class="s5_345"
>]</text>

<text 
x="76" 
y="896" 
class="s5_345"
>]</text>

<text 
x="55" 
y="949" 
class="s1_345"
>And we’ll try to find</text>

<text 
x="242" 
y="949" 
dx="0,0,6.1,0,6.1" 
class="s2_345"
>K = 4</text>

<text 
x="300" 
y="949" 
class="s1_345"
>topics.</text>

<text 
x="55" 
y="990" 
class="s1_345"
>In order to calculate the sampling weights, we’ll need to keep track of several counts.</text>

<text 
x="55" 
y="1017" 
dx="0,0,0,0,-1.2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0" 
class="s1_345"
>Let’s first create the data structures for them.</text>

<text 
x="55" 
y="1056" 
class="s1_345"
>How many times each topic is assigned to each document:</text>

<text 
x="76" 
y="1101" 
dx="0,0,4.6,0,4.6,0,0,0,0,4.6,0,0,4.6,0,0,0,0,0,0,0,0,0,4.6,0,0,0,4.6,0,0,0,4.6,0,0,0,0,4.6,0,0,0,0,0,0,0" 
class="s9_345"
># a list of Counters, one for each document</text>

<text 
x="76" 
y="1116" 
class="s6_345"
>document_topic_counts</text>

<text 
x="250" 
y="1116" 
dx="0,0,4.6" 
class="s5_345"
>= [</text>

<text 
x="274" 
y="1116" 
class="s6_345"
>Counter</text>

<text 
x="329" 
y="1116" 
class="s5_345"
>()</text>

<text 
x="353" 
y="1116" 
class="s3_345"
>for</text>

<text 
x="385" 
y="1116" 
class="s6_345"
>_</text>

<text 
x="401" 
y="1116" 
class="s10_345"
>in</text>

<text 
x="424" 
y="1116" 
class="s6_345"
>documents</text>

<text 
x="495" 
y="1116" 
class="s5_345"
>]</text>

<text 
x="55" 
y="1169" 
class="s1_345"
>How many times each word is assigned to each topic:</text>

<text 
x="76" 
y="1214" 
dx="0,0,4.6,0,4.6,0,0,0,0,4.6,0,0,4.6,0,0,0,0,0,0,0,0,0,4.6,0,0,0,4.6,0,0,0,4.6,0,0,0,0,4.6,0,0,0,0" 
class="s9_345"
># a list of Counters, one for each topic</text>



<!-- Any embedded fonts defined here -->
<style type="text/css" ><![CDATA[

@font-face {
	font-family: LiberationMono-Bold_1w;
	src: url("fonts/LiberationMono-Bold_1w.woff") format("woff");
}

@font-face {
	font-family: LiberationMono_1q;
	src: url("fonts/LiberationMono_1q.woff") format("woff");
}

@font-face {
	font-family: LiberationMono-Italic_10;
	src: url("fonts/LiberationMono-Italic_10.woff") format("woff");
}

@font-face {
	font-family: LiberationSerif_e;
	src: url("fonts/LiberationSerif_e.woff") format("woff");
}

]]></style>

</svg>
